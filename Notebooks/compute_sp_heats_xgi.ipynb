{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle \n",
    "\n",
    "sys.path.append(sys.path[0] + \"/..\")  # Adds higher directory to python modules path.\n",
    "\n",
    "import numpy as np\n",
    "from Scripts import renormalize, scomplex\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.rcParams[\"text.usetex\"] = False\n",
    "\n",
    "\n",
    "colors = [\"#003F5C\",\"#2F4B7C\",\"#665191\",\"#A05195\",\"#D45087\",\"#F95D6A\",\"#FF7C43\",\"#FFA600\"]\n",
    "colors_sequential = colors + colors + colors + colors \n",
    "colors = [\"#02405c\", \"#fea600\", \"#a20655\", \"#5e96c5\", \"#4b3596\", \"#fa6ca9\", \"#8d6cf6\"]\n",
    "colors_curves = colors+ colors+ colors+ colors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hg_to_sc(H):\n",
    "    H.cleanup()\n",
    "\n",
    "    sc = {}\n",
    "    sc[\"nodes\"] = np.sort(np.array([H.nodes]).T,0)\n",
    "    sc[\"n0\"] = sc[\"nodes\"].shape[0]\n",
    "    keys = [\"edges\",\"faces\",\"tetrahedra\",\"4-simplices\"]\n",
    "\n",
    "    for k in keys:\n",
    "        sc[k] = []\n",
    "    for e in H.edges.members():\n",
    "        if len(e) <= 5:\n",
    "            sc[keys[len(e)-2]].append(list(e))\n",
    "\n",
    "    for i,k in enumerate(keys):\n",
    "        if len(sc[k]) == 0:\n",
    "            sc[k] = np.zeros((0,i+2))\n",
    "        else:\n",
    "            sc[k] = np.unique(np.sort(np.array(sc[k]),1),axis =0)\n",
    "        \n",
    "        sc[f\"n{i+1}\"] = sc[k].shape[0] \n",
    "    return sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacians(dim = 2):\n",
    "    return [str(a)+str(b) for a in range(dim+1) for b in range(dim+1) if a != b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGI Hypergraphs test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_hg = ['congress-bills', 'contact-high-school', 'contact-primary-school', 'diseasome', 'disgenenet','email-enron', 'email-eu', 'hospital-lyon', 'house-bills', 'house-committees', 'hypertext-conference', 'invs13', 'invs15', 'malawi-village','ndc-classes', 'ndc-substances', 'science-gallery', 'senate-bills', 'senate-committees','sfhh-conference']\n",
    "true_names_hg = ['US Congress Bills', 'High school contacts', 'Primary school contact', 'Diseasome', 'Disgenenet', 'Enron email', 'Eu email', 'Hospital contacts', 'House bills', 'House committees', 'Hypertext contacts', 'InVS13', 'InVS15', 'Malawi contacts', 'Classes of NDC', 'Substances of NDC', 'Science Gallery', 'Senate bills', 'Senate committees', 'SFHH conference']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import hypergraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Data/Datasets/xgi/xgi_sc.pkl\", \"rb\") as f:\n",
    "    scs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Compute Laplacians an Sp Heats</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datasets = 20\n"
     ]
    }
   ],
   "source": [
    "N_data = len(names_hg)\n",
    "print('Number of datasets =', N_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taumin = -3 # Heat curve starts from 10**taumin\n",
    "taumax = 5 # Heat curve ends at 10**taumax\n",
    "ntau = 200 # Number of taus to consider in the interval\n",
    "SP_HEATS = {}\n",
    "for name in tqdm(names_hg):\n",
    "    sc = scs[name]\n",
    "\n",
    "    smax = 0 # Hypergraph dimension\n",
    "    for i in range(5):\n",
    "        if sc[f'n{i}'] != 0:\n",
    "            smax +=1\n",
    "    # Define strings which specify the cross-order Laplacians to consider\n",
    "    laplacians_types = laplacians(smax - 1)\n",
    "\n",
    "    C_curves = {l : [] for l in laplacians_types}\n",
    "    for idl,l in tqdm(enumerate(laplacians_types)):    \n",
    "        L = scomplex.XO_laplacian_hg(sc, k=int(l[0]), l=int(l[1]))    \n",
    "        D,__ = np.linalg.eigh(L)\n",
    "        D = np.abs(D)\n",
    "        entropic_susceptibility,tau_space,__  = renormalize.compute_entropic_C(D,taumin,taumax,ntau)\n",
    "        C_curves[l] = entropic_susceptibility\n",
    "    SP_HEATS[name] = C_curves\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save specific heats for the hypergraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/C_curves/RealData/xgi/xgi_spheats.pkl', \"wb\") as f:\n",
    "    pickle.dump(SP_HEATS, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taumin = -3 # Heat curve starts from 10**taumin\n",
    "taumax = 5 # Heat curve ends at 10**taumax\n",
    "ntau = 200 # Number of taus to consider in the interval\n",
    "nrep = 5\n",
    "\n",
    "SP_HEATS_CM = {}\n",
    "\n",
    "for name in tqdm(names_hg):\n",
    "    sc = scs[name]\n",
    "    smax = 0\n",
    "    for i in range(5):\n",
    "        if sc[f'n{i}'] != 0:\n",
    "            smax +=1\n",
    "\n",
    "\n",
    "    # Define strings which specify the cross-order Laplacians to consider\n",
    "    laplacians_types = laplacians(smax - 1)\n",
    "\n",
    "    C_curves = {l : [] for l in laplacians_types}\n",
    "\n",
    "    for idl,l in tqdm(enumerate(laplacians_types)): \n",
    "        A = scomplex.adjacency_of_order_hg(sc, k=int(l[0]), l=int(l[1]))\n",
    "        for n in tqdm(range(nrep)):\n",
    "            # # Configuration model\n",
    "            Gcm = nx.Graph(A)\n",
    "            Gcm = nx.configuration_model([val for (__, val) in Gcm.degree()])\n",
    "            L = nx.laplacian_matrix(Gcm).todense()\n",
    "            D,__ = np.linalg.eigh(L)\n",
    "            D = np.abs(D)\n",
    "            entropic_susceptibility,tau_space,__  = renormalize.compute_entropic_C(D,taumin,taumax,ntau)\n",
    "            C_curves[l].append(entropic_susceptibility)\n",
    "\n",
    "    SP_HEATS_CM[name] = C_curves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/C_curves/RealData/xgi/xgi_spheats_cm.pkl', \"wb\") as f:\n",
    "    pickle.dump(SP_HEATS_CM, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
